<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Media Description with Chrome Built-in API</title>
</head>
<body>
    <h1>Chrome Built-In API Media Description</h1>
    <p>Select an image or audio file, or use your webcam/mic to capture media, to describe it using the Language Model API.</p>

    <h3>Image Input</h3>
    <input type="file" id="myImageInput" accept="image/*" />
    <button onclick="myStartWebcam()">Start Webcam</button>
    <button id="myCaptureImageButton" onclick="myCaptureImage()" style="display: none;">Capture Image</button>

    <h3>Audio Input</h3>
    <input type="file" id="myAudioInput" accept="audio/*" />
    <button id="myStartRecordingButton" onclick="myStartAudioRecording()">Start Mic Recording</button>
    <button id="myStopRecordingButton" onclick="myStopAudioRecording()" style="display: none;">Stop Mic Recording</button>
    <audio id="myAudioPreview" controls style="display: none;"></audio>

    <hr>

    <button id="myDescribeButton" onclick="myStartDescription()">Describe Media</button>
    <button id="myStopButton" onclick="myStopDescription()" style="display: none;">Stop Description</button>

    <div id="myStatus">Status here</div>
    <h2>Description:</h2>
    <p id="myOutputText"></p>

    <img id="myImagePreview" alt="Image Preview" style="display: none; max-width: 100%; height: auto;" />
    <video id="myWebcamPreview" style="display: none; max-width: 100%; height: auto;"></video>
    <canvas id="myCanvas" style="display: none;"></canvas>

    <script type="module">
        // Element variables
        const myImageInput = document.getElementById('myImageInput');
        const myImagePreview = document.getElementById('myImagePreview');
        const myAudioInput = document.getElementById('myAudioInput');
        const myAudioPreview = document.getElementById('myAudioPreview');
        const myOutputText = document.getElementById('myOutputText');
        const myStatus = document.getElementById('myStatus');
        const myWebcamPreview = document.getElementById('myWebcamPreview');
        const myCaptureImageButton = document.getElementById('myCaptureImageButton');
        const myStartRecordingButton = document.getElementById('myStartRecordingButton');
        const myStopRecordingButton = document.getElementById('myStopRecordingButton');
        const myDescribeButton = document.getElementById('myDescribeButton');
        const myStopButton = document.getElementById('myStopButton');
        const myCanvas = document.getElementById('myCanvas');

        // State variables
        let myImageBlob = null;
        let myAudioBlob = null;
        let myTimerId = null;
        let myAnalysisTimerId = null;
        let myAbortController = null;
        let myTimeoutId = null;
        let myMediaRecorder = null;
        let myAudioChunks = [];

        // Image file selection handler
        myImageInput.onchange = async (event) => {
            const myFile = event.target.files[0];
            if (myFile) {
                myImageBlob = myFile;
                myAudioBlob = null; // Clear other media
                myImagePreview.src = URL.createObjectURL(myFile);
                myImagePreview.style.display = 'block';
                myWebcamPreview.style.display = 'none';
                myAudioPreview.style.display = 'none';
                myCaptureImageButton.style.display = 'none';
                myOutputText.textContent = 'Image selected. Ready to describe...';
                myStatus.textContent = '';
            }
        };

        // Audio file selection handler
        myAudioInput.onchange = async (event) => {
            const myFile = event.target.files[0];
            if (myFile) {
                myAudioBlob = myFile;
                myImageBlob = null; // Clear other media
                myAudioPreview.src = URL.createObjectURL(myFile);
                myAudioPreview.style.display = 'block';
                myImagePreview.style.display = 'none';
                myWebcamPreview.style.display = 'none';
                myCaptureImageButton.style.display = 'none';
                myOutputText.textContent = 'Audio file selected. Ready to describe...';
                myStatus.textContent = '';
            }
        };

        // Start webcam functionality
        window.myStartWebcam = async () => {
            try {
                const myStream = await navigator.mediaDevices.getUserMedia({ video: true });
                myWebcamPreview.srcObject = myStream;
                myWebcamPreview.style.display = 'block';
                myWebcamPreview.play();
                myCaptureImageButton.style.display = 'block';
                myImageInput.style.display = 'none';
                myImagePreview.style.display = 'none';
                myAudioInput.style.display = 'none';
                myAudioPreview.style.display = 'none';
                myOutputText.textContent = 'Webcam active. Click "Capture Image" to continue.';
                myImageBlob = null;
                myAudioBlob = null;
            } catch (error) {
                myOutputText.textContent = 'Error starting webcam: ' + error.message;
            }
        };

        // Capture image from webcam
        window.myCaptureImage = () => {
            myCanvas.width = myWebcamPreview.videoWidth;
            myCanvas.height = myWebcamPreview.videoHeight;
            const myContext = myCanvas.getContext('2d');
            myContext.drawImage(myWebcamPreview, 0, 0, myCanvas.width, myCanvas.height);
            myCanvas.toBlob((myBlob) => {
                myImageBlob = myBlob;
                myAudioBlob = null;
                myImagePreview.src = URL.createObjectURL(myBlob);
                myImagePreview.style.display = 'block';
                myWebcamPreview.pause();
                myWebcamPreview.srcObject.getTracks().forEach(track => track.stop());
                myWebcamPreview.style.display = 'none';
                myCaptureImageButton.style.display = 'none';
                myImageInput.style.display = 'block';
                myOutputText.textContent = 'Image captured. Ready to describe...';
            }, 'image/jpeg');
        };

        // Start audio recording
        window.myStartAudioRecording = async () => {
            try {
                const myStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                myMediaRecorder = new MediaRecorder(myStream);
                myAudioChunks = [];
                myMediaRecorder.ondataavailable = (event) => {
                    myAudioChunks.push(event.data);
                };
                myMediaRecorder.onstop = () => {
                    myAudioBlob = new Blob(myAudioChunks, { type: 'audio/mpeg' });
                    myAudioPreview.src = URL.createObjectURL(myAudioBlob);
                    myAudioPreview.style.display = 'block';
                    myOutputText.textContent = 'Audio recorded. Ready to describe...';
                    myStatus.textContent = '';
                    myImageBlob = null;
                    myAudioInput.style.display = 'block';
                    myImageInput.style.display = 'block';
                };
                myMediaRecorder.start();
                myStatus.textContent = 'Recording audio...';
                myStartRecordingButton.style.display = 'none';
                myStopRecordingButton.style.display = 'block';
            } catch (error) {
                myOutputText.textContent = 'Error starting mic: ' + error.message;
            }
        };

        // Stop audio recording
        window.myStopAudioRecording = () => {
            if (myMediaRecorder && myMediaRecorder.state !== 'inactive') {
                myMediaRecorder.stop();
                myMediaRecorder.stream.getTracks().forEach(track => track.stop());
            }
            myStatus.textContent = 'Recording stopped.';
            myStartRecordingButton.style.display = 'block';
            myStopRecordingButton.style.display = 'none';
        };

        // Stop description process
        window.myStopDescription = () => {
            if (myAbortController) {
                myAbortController.abort();
                myAbortController = null;
            }
            clearInterval(myTimerId);
            clearInterval(myAnalysisTimerId);
            clearTimeout(myTimeoutId);
            myStatus.textContent = 'Process stopped.';
            myDescribeButton.disabled = false;
            myStopButton.style.display = 'none';
        };

        // Start the description process
        window.myStartDescription = async () => {
            if (!myImageBlob && !myAudioBlob) {
                myOutputText.textContent = 'Please select or capture media first.';
                return;
            }
            myDescribeButton.disabled = true;
            myStopButton.style.display = 'block';
            myAbortController = new AbortController();
            let mySeconds = 0;
            myOutputText.textContent = 'Model is being downloaded...';
            myTimerId = setInterval(() => {
                mySeconds++;
                myOutputText.textContent = `Model is being downloaded... ${mySeconds} seconds`;
            }, 1000);
            myTimeoutId = setTimeout(() => {
                if (myAbortController) {
                    myAbortController.abort();
                }
            }, 30000); // 30 second timeout

            try {
                const myExpectedInputs = myImageBlob ? [{ type: 'image' }] : [{ type: 'audio' }];
                // Log information about the AI model and its parameters
                console.log('Attempting to create a Language Model session with expected inputs:', myExpectedInputs);
                console.log('Note: The Language Model API does not expose parameters like topk or temperature.');

                const mySession = await LanguageModel.create({
                    expectedInputs: myExpectedInputs,
                });
                // Log information after the session is successfully created
                console.log('Language Model session created successfully. Ready for prompt streaming.');

                clearInterval(myTimerId);
                myOutputText.textContent = '';
                let myAnalysisSeconds = 0;
                myAnalysisTimerId = setInterval(() => {
                    myAnalysisSeconds++;
                    myStatus.textContent = `Analyzing... ${myAnalysisSeconds} seconds`;
                }, 1000);

                const myContentType = myImageBlob ? 'image' : 'audio';
                const myContentValue = myImageBlob || myAudioBlob;
                const myPromptValue = `Describe this ${myContentType} as completely as you can`;

                // Log the prompt being sent to the model
                console.log(`Sending prompt to the model: "${myPromptValue}"`);

                const myStream = mySession.promptStreaming([
                    {
                        role: 'user',
                        content: [
                            {
                                type: myContentType,
                                value: myContentValue,
                            },
                            {
                                type: 'text',
                                value: myPromptValue,
                            },
                        ],
                    },
                ], { signal: myAbortController.signal }, { outputLanguage: 'en' }); // Added outputLanguage parameter

                for await (const myChunk of myStream) {
                    myOutputText.append(myChunk);
                }

                clearInterval(myAnalysisTimerId);
                clearTimeout(myTimeoutId);
                myStatus.textContent = 'Analysis complete.';
                // Log when the description is finished
                console.log('Description finished. Output is now on the page.');

            } catch (error) {
                clearInterval(myTimerId);
                clearInterval(myAnalysisTimerId);
                clearTimeout(myTimeoutId);
                if (error.name === 'AbortError') {
                    myStatus.textContent = 'Description process was stopped.';
                    console.error('The user aborted the process.');
                } else {
                    myStatus.textContent = 'An error occurred. Please check the console for details.';
                    console.error('An error occurred during the model interaction:', error);
                }
            } finally {
                myAbortController = null;
                myDescribeButton.disabled = false;
                myStopButton.style.display = 'none';
            }
        };
    </script>
</body>
</html>
